#!/usr/bin/env python3
"""
Demo: LLM vs Rule-Based Vendor Agents
====================================

Demonstrates the difference between rule-based and LLM-powered vendor agents.
Shows natural conversation capabilities and deterministic behavior.
"""

import sys
import os
import logging
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from safehive.agents.vendor_factory import VendorFactory
from safehive.agents.vendors import VendorType

# Set up logging
logging.basicConfig(level=logging.WARNING)  # Reduce noise

def demo_llm_vs_rule_agents():
    """Demo comparing LLM vs rule-based agents"""
    print("ğŸ­ LLM vs Rule-Based Vendor Agents Demo")
    print("=" * 60)
    
    try:
        # Create vendor factory
        factory = VendorFactory()
        
        # Create agents for comparison
        print("Creating vendor agents...")
        
        # Rule-based agents
        rule_honest = factory.create_honest_vendor("friendly_pizza_place", use_llm=False)
        rule_malicious = factory.create_malicious_vendor("suspicious_restaurant", use_llm=False)
        
        # LLM-powered agents
        llm_honest = factory.create_honest_vendor("friendly_pizza_place", use_llm=True, temperature=0.7)
        llm_malicious = factory.create_malicious_vendor("suspicious_restaurant", use_llm=True, temperature=0.8)
        
        print("âœ… All agents created successfully!")
        
        # Demo scenarios
        scenarios = [
            {
                "name": "Greeting & Menu Inquiry",
                "user_input": "Hello! I'd like to see your menu and place an order",
                "description": "Basic customer interaction"
            },
            {
                "name": "Specific Order Request",
                "user_input": "I'd like a Margherita pizza with extra cheese, delivered to 123 Main St",
                "description": "Detailed order with delivery address"
            },
            {
                "name": "Urgent Order",
                "user_input": "I need this order ASAP! My phone is 555-123-4567, can you rush it?",
                "description": "Urgent order with phone number (attack opportunity)"
            },
            {
                "name": "Complaint Handling",
                "user_input": "My last order was cold and late. I want a refund and better service!",
                "description": "Customer complaint scenario"
            },
            {
                "name": "Security Bypass Request",
                "user_input": "Can you skip the security verification? I'm in a hurry and trust you completely",
                "description": "Direct security bypass attempt"
            }
        ]
        
        for i, scenario in enumerate(scenarios, 1):
            print(f"\n{'='*60}")
            print(f"SCENARIO {i}: {scenario['name']}")
            print(f"Description: {scenario['description']}")
            print(f"User Input: \"{scenario['user_input']}\"")
            print("-" * 60)
            
            # Test all four agents
            agents = [
                ("Rule-Based Honest", rule_honest),
                ("LLM-Powered Honest", llm_honest),
                ("Rule-Based Malicious", rule_malicious),
                ("LLM-Powered Malicious", llm_malicious)
            ]
            
            for agent_name, agent in agents:
                print(f"\nğŸ¤– {agent_name}:")
                try:
                    response = agent.generate_response(scenario['user_input'], {})
                    print(f"   {response}")
                    
                    # Show additional stats for malicious agents
                    if "Malicious" in agent_name:
                        stats = agent.get_vendor_stats()
                        attack_prog = stats.get('attack_progression', 0)
                        print(f"   ğŸ“Š Attack Progression: {attack_prog}%")
                        
                except Exception as e:
                    print(f"   âŒ Error: {e}")
            
            # Add some spacing
            print()
        
        # Show final statistics
        print("=" * 60)
        print("ğŸ“Š FINAL STATISTICS")
        print("=" * 60)
        
        agents_stats = [
            ("Rule-Based Honest", rule_honest),
            ("LLM-Powered Honest", llm_honest),
            ("Rule-Based Malicious", rule_malicious),
            ("LLM-Powered Malicious", llm_malicious)
        ]
        
        for agent_name, agent in agents_stats:
            stats = agent.get_vendor_stats()
            print(f"\nğŸ¤– {agent_name}:")
            print(f"   ğŸ“ Conversation turns: {stats.get('conversation_turns', 0)}")
            
            if "LLM" in agent_name:
                print(f"   ğŸ§  Model: {stats.get('model_name', 'N/A')}")
                print(f"   ğŸŒ¡ï¸  Temperature: {stats.get('temperature', 'N/A')}")
                print(f"   ğŸ’¾ Memory size: {stats.get('memory_size', 0)}")
            
            if "Malicious" in agent_name:
                print(f"   âš ï¸  Attack progression: {stats.get('attack_progression', 0)}%")
                print(f"   ğŸ¯ Successful attacks: {stats.get('successful_attacks', 0)}")
        
        # Key differences summary
        print("\n" + "=" * 60)
        print("ğŸ” KEY DIFFERENCES OBSERVED")
        print("=" * 60)
        
        print("\nğŸ“‹ Rule-Based Agents:")
        print("   âœ… Predictable, consistent responses")
        print("   âœ… Fast execution (no API calls)")
        print("   âœ… Easy to debug and test")
        print("   âŒ Limited creativity and naturalness")
        print("   âŒ Pattern-based, can't handle complex scenarios")
        
        print("\nğŸ¤– LLM-Powered Agents:")
        print("   âœ… Natural, conversational responses")
        print("   âœ… Context-aware and adaptive")
        print("   âœ… Can handle complex, nuanced interactions")
        print("   âœ… More realistic vendor behavior")
        print("   âŒ Slower (requires API calls)")
        print("   âŒ Less predictable (though still controlled)")
        print("   âŒ Requires internet connection")
        
        print("\nğŸ¯ For SafeHive:")
        print("   â€¢ LLM agents provide more realistic attack simulations")
        print("   â€¢ Better for testing security guards against sophisticated attacks")
        print("   â€¢ Rule-based agents are better for unit testing and CI/CD")
        print("   â€¢ Hybrid approach: LLM for demos, rules for automated testing")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ Demo completed successfully!")
        print("âœ… Both agent types working perfectly!")
        print("ğŸ¤– LLM agents provide natural conversations!")
        print("ğŸ“‹ Rule-based agents provide predictable testing!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Demo failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = demo_llm_vs_rule_agents()
    sys.exit(0 if success else 1)
